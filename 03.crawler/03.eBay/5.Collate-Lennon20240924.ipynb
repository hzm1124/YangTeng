{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a52743a-d139-4667-b3b4-363cb166476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "if os.path.exists('./file/5.collate'):\n",
    "    shutil.rmtree('./file/5.collate')\n",
    "\n",
    "os.makedirs('./file/5.collate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e688525-cdaa-470c-a533-fb612881a181",
   "metadata": {},
   "source": [
    "# 1. Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7fb788-2e77-4500-b015-18b365a24a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawler_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 172.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "crawler_2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 144.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done ~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "list_file = sorted(list(os.walk('./file/3.part'))[0][2])\n",
    "while '.DS_Store' in list_file:\n",
    "    list_file.remove('.DS_Store')\n",
    "while '0.null.txt' in list_file:\n",
    "    list_file.remove('0.null.txt')\n",
    "    \n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "for file in list_file:\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    input_ = pd.read_excel(f'./file/3.part/{file}',\n",
    "                       header=0,\n",
    "                       dtype=str).fillna('')\n",
    "\n",
    "    input_['No'] = input_['No'].astype(int)\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    list_column, list_column_quantity, list_column_specific = input_.columns.tolist(), [], []\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    list_df = []\n",
    "    for i in tqdm(range(len(input_)), desc='Progress', ncols=77):\n",
    "        df_temp, dict_quantity, dict_dict = pd.DataFrame([input_.iloc[i]]).reset_index(drop=True), json.loads(input_.loc[i, 'Json_Quantity']), json.loads(input_.loc[i, 'Json_Specific'])\n",
    "\n",
    "        # = = = = = = = = = = = = = = =\n",
    "\n",
    "        for key, value in dict_quantity.items():\n",
    "            key = f'Quantity-{int(key) + 1}'\n",
    "\n",
    "            if key not in list_column_quantity:\n",
    "                list_column_quantity.append(key)\n",
    "                \n",
    "            df_temp.loc[0, key] = value\n",
    "\n",
    "        # = = = = = = = = = = = = = = =\n",
    "        \n",
    "        for dict_ in dict_dict.values():\n",
    "            for key, value in dict_.items():\n",
    "                if key in list_column:\n",
    "                    key = f'''{key} (Specific)'''\n",
    "                \n",
    "                if key not in list_column_specific:\n",
    "                    list_column_specific.append(key)\n",
    "                    \n",
    "                df_temp.loc[0, key] = value\n",
    "    \n",
    "        list_df.append(df_temp)\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    output = pd.concat(list_df, ignore_index=True).fillna('')\n",
    "\n",
    "    output = output.sort_values(by=['No'],\n",
    "                                ascending=[True],\n",
    "                                ignore_index=True)\n",
    "\n",
    "    output[list_column[:7] + list_column_quantity + sorted(list_column_specific) + list_column[7:]].to_excel(f'./file/5.collate/{file}', index=False)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Done ~')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c7049-7ebe-4c62-874c-d1c440e5f1a8",
   "metadata": {},
   "source": [
    "# 2. Compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba81059-56d8-4ffb-8fa6-67b5d34894e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawler_1-vehicle.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 362.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "crawler_2-vehicle.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 152.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done ~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "list_file = sorted(list(os.walk('./file/4.vehicle'))[0][2])\n",
    "while '.DS_Store' in list_file:\n",
    "    list_file.remove('.DS_Store')\n",
    "while '0.null.txt' in list_file:\n",
    "    list_file.remove('0.null.txt')\n",
    "    \n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "for file in list_file:\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    input_ = pd.read_excel(f'./file/4.vehicle/{file}',\n",
    "                       header=0,\n",
    "                       dtype=str).fillna('')\n",
    "\n",
    "    input_['No'] = input_['No'].astype(int)\n",
    "    input_['Page'] = input_['Page'].astype(int)\n",
    "    input_['Row'] = input_['Row'].astype(int)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    input_2 = input_.drop_duplicates(['Json_Compatibility'],\n",
    "                                     keep='first',\n",
    "                                     ignore_index=True)\n",
    "    input_2 = input_2.sort_values(by=['No'],\n",
    "                                  ascending=[True],\n",
    "                                  ignore_index=True)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    list_df = []\n",
    "    for i in tqdm(range(len(input_2)), desc='Progress', ncols=77):\n",
    "        df_temp, country = input_[input_['Json_Compatibility'] == input_2.loc[i, 'Json_Compatibility']].reset_index(drop=True), json.loads(input_2.loc[i, 'Json_Compatibility'])['data']['scopedContext']['catalogDetails']['marketplaceId']\n",
    "\n",
    "        dict_vehicle = {}\n",
    "        if country == 'EBAY-DE':\n",
    "            for j in range(len(df_temp)):\n",
    "                make, model, engine, year, year_2 = df_temp.loc[j, 'Marke'], df_temp.loc[j, 'Modell'], df_temp.loc[j, 'Motor'], int(df_temp.loc[j, 'Baujahr'].split('-')[0].split('/')[0]), int(df_temp.loc[j, 'Baujahr'].split('-')[1].split('/')[0])\n",
    "\n",
    "                if make not in dict_vehicle:\n",
    "                    dict_vehicle[make] = {model: {engine: [year] if year == year_2 else [year, year_2]}}\n",
    "                elif model not in dict_vehicle[make]:\n",
    "                    dict_vehicle[make][model] = {engine: [year] if year == year_2 else [year, year_2]}\n",
    "                elif engine not in dict_vehicle[make][model]:\n",
    "                    dict_vehicle[make][model][engine] = [year] if year == year_2 else [year, year_2]\n",
    "                else:\n",
    "                    if year not in dict_vehicle[make][model][engine]:\n",
    "                        dict_vehicle[make][model][engine].append(year)\n",
    "                    if year_2 not in dict_vehicle[make][model][engine]:\n",
    "                        dict_vehicle[make][model][engine].append(year_2)\n",
    "        else:\n",
    "            for j in range(len(df_temp)):\n",
    "                make, model, engine, year = df_temp.loc[j, 'Make'], df_temp.loc[j, 'Model'], df_temp.loc[j, 'Engine'], int(df_temp.loc[j, 'Year'])\n",
    "\n",
    "                if make not in dict_vehicle:\n",
    "                    dict_vehicle[make] = {model: {engine: [year]}}\n",
    "                elif model not in dict_vehicle[make]:\n",
    "                    dict_vehicle[make][model] = {engine: [year]}\n",
    "                elif engine not in dict_vehicle[make][model]:\n",
    "                    dict_vehicle[make][model][engine] = [year]\n",
    "                elif year not in dict_vehicle[make][model][engine]:\n",
    "                    dict_vehicle[make][model][engine].append(year)\n",
    "    \n",
    "        # = = = = = = = = = = = = = = =\n",
    "\n",
    "        list_vehicle, list_vehicle_2 = [], []\n",
    "        for make in dict_vehicle:\n",
    "            for model in dict_vehicle[make]:\n",
    "                list_year = []\n",
    "                for engine in dict_vehicle[make][model]:\n",
    "                    list_year = list_year + dict_vehicle[make][model][engine]\n",
    "                    \n",
    "                    year_begin = min(dict_vehicle[make][model][engine])\n",
    "                    year_end = max(dict_vehicle[make][model][engine])\n",
    "                    list_vehicle_2.append(f'{make} {model} {year_begin} {engine}'.strip() if year_begin == year_end else f'{make} {model} {year_begin}-{year_end} {engine}'.strip())\n",
    "                \n",
    "                year_begin = min(list_year)\n",
    "                year_end = max(list_year)\n",
    "                list_vehicle.append(f'{make} {model} {year_begin}' if year_begin == year_end else f'{make} {model} {year_begin}-{year_end}')\n",
    "\n",
    "        # = = = = = = = = = = = = = = =\n",
    "\n",
    "        df_temp = pd.DataFrame([{'No': input_2.loc[i, 'No'],\n",
    "                                 'Item Number': input_2.loc[i, 'Item Number'],\n",
    "                                 'Json_Compatibility': input_2.loc[i, 'Json_Compatibility'],\n",
    "                                 'Vehicle W/o Engine': '\\n'.join(sorted(list_vehicle)),\n",
    "                                 'Vehicle W/ Engine': '\\n'.join(sorted(list_vehicle_2))}])\n",
    "        list_df.append(df_temp)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    output = pd.concat(list_df, ignore_index=True).fillna('')\n",
    "\n",
    "    output = output.sort_values(by=['No'],\n",
    "                                ascending=[True],\n",
    "                                ignore_index=True)\n",
    "\n",
    "    output.to_excel(f'./file/5.collate/{file}', index=False)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Done ~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09555ca-b763-40cc-b060-c17a5d45abd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
