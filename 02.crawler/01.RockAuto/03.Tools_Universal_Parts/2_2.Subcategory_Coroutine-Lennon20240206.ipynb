{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c398ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数量：26\n",
      "\n",
      "Body & Lamp Assembly  <->  [ok] - 剩余数量：23 - 当前时间：17:00:50\n",
      "Brake & Wheel Hub  <->  [ok] - 剩余数量：22 - 当前时间：17:00:51\n",
      "Cooling System  <->  [ok] - 剩余数量：21 - 当前时间：17:00:53\n",
      "Drivetrain  <->  [ok] - 剩余数量：20 - 当前时间：17:00:54\n",
      "Electrical  <->  [ok] - 剩余数量：19 - 当前时间：17:00:55\n",
      "Electrical-Bulb & Socket  <->  [ok] - 剩余数量：18 - 当前时间：17:00:58\n",
      "Electrical-Connector  <->  [ok] - 剩余数量：17 - 当前时间：17:01:00\n",
      "Electrical-Switch & Relay  <->  [ok] - 剩余数量：16 - 当前时间：17:01:02\n",
      "Engine  <->  [ok] - 剩余数量：15 - 当前时间：17:01:04\n",
      "Exhaust & Emission  <->  [ok] - 剩余数量：14 - 当前时间：17:01:07\n",
      "Fuel & Air  <->  [ok] - 剩余数量：13 - 当前时间：17:01:09\n",
      "Garage Equipment  <->  [ok] - 剩余数量：12 - 当前时间：17:01:11\n",
      "Hardware  <->  [ok] - 剩余数量：11 - 当前时间：17:01:13\n",
      "Heat & Air Conditioning  <->  [ok] - 剩余数量：10 - 当前时间：17:01:15\n",
      "Hoses/Lines & Clamps  <->  [ok] - 剩余数量：9 - 当前时间：17:01:21\n",
      "Apparel & Gifts  <->  [ok] - 剩余数量：8 - 当前时间：17:01:22\n",
      "Ignition  <->  [ok] - 剩余数量：7 - 当前时间：17:01:23\n",
      "Literature  <->  [ok] - 剩余数量：6 - 当前时间：17:01:24\n",
      "Interior  <->  [ok] - 剩余数量：5 - 当前时间：17:01:24\n",
      "Suspension  <->  [ok] - 剩余数量：4 - 当前时间：17:01:26\n",
      "Steering  <->  [ok] - 剩余数量：3 - 当前时间：17:01:26\n",
      "Transmission-Manual  <->  [ok] - 剩余数量：2 - 当前时间：17:01:28\n",
      "Wheel  <->  [ok] - 剩余数量：1 - 当前时间：17:01:29\n",
      "Transmission-Automatic  <->  [ok] - 剩余数量：0 - 当前时间：17:01:34\n",
      "Belt Drive  <->  [ok] - 剩余数量：0 - 当前时间：17:01:37\n",
      "Wiper & Washer  <->  [ok] - 剩余数量：0 - 当前时间：17:01:38\n",
      "\n",
      "爬虫输出中\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/20/g09tvx4s7mdd977ps185l3_r0000gn/T/ipykernel_56120/2347780365.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'爬虫输出中'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0moutput_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_correct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0moutput_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_correct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'No.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0moutput_correct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./2.subategory_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d_%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0moutput_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/YangTeng/code/venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6736\u001b[0m                 \u001b[0;34mf\"Length of ascending ({len(ascending)})\"\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6737\u001b[0m                 \u001b[0;34mf\" != length of by ({len(by)})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6738\u001b[0m             )\n\u001b[1;32m   6739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6740\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6742\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6743\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/YangTeng/code/venv/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m-> 6740\u001b[0;31m     def sort_values(\n\u001b[0m\u001b[1;32m   6741\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6742\u001b[0m         \u001b[0mby\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexLabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6743\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/YangTeng/code/venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "from gevent import monkey\n",
    "monkey.patch_all(thread=False)\n",
    "from gevent.queue import Queue\n",
    "import gevent\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../00.module')\n",
    "import UA\n",
    "import Proxy\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "output_correct = pd.DataFrame()\n",
    "\n",
    "output_error = pd.DataFrame()\n",
    "\n",
    "input_ = pd.read_excel('./1.category.xlsx',\n",
    "                       header=0,\n",
    "                       dtype=str).fillna('')\n",
    "\n",
    "length = len(input_)\n",
    "\n",
    "print('总数量：' + str(length))\n",
    "print()\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "from urllib.parse import quote\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from lxml import etree\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "work = Queue()\n",
    "for i in range(length):\n",
    "    work.put_nowait(i)\n",
    "\n",
    "def crawler():\n",
    "    global output_correct, output_error\n",
    "    \n",
    "    while not work.empty():\n",
    "        i = work.get_nowait()\n",
    "        \n",
    "        # = = = = = = = = = = = = = = =\n",
    "        \n",
    "        crawler_status = 'error'\n",
    "        for _ in range(101):\n",
    "            try:\n",
    "                jsn = '{\"jsn\":{\"tab\":\"extras\",\"groupname\":\"' + input_.loc[i, 'Category'] + '\",\"nodetype\":\"groupname\"}}'\n",
    "\n",
    "                payload = {'func': 'navnode_fetch',\n",
    "                           'payload': jsn,\n",
    "                           'api_json_request': '1'}\n",
    "\n",
    "                resp = requests.post('https://www.rockauto.com/catalog/catalogapi.php',\n",
    "                                     data=payload,\n",
    "                                     headers=UA.get_User_Agent_Requests(),\n",
    "                                     proxies=Proxy.get_Proxy_Requests()).text\n",
    "\n",
    "                resp = json.loads(resp)\n",
    "                \n",
    "                # = = = = = = = = = = = = = = =\n",
    "                \n",
    "                html = resp['html_fill_sections']['navchildren[]']\n",
    "                \n",
    "                soup = BeautifulSoup(html, 'lxml')\n",
    "                \n",
    "                # = = = = = = = = = = = = = = =\n",
    "                \n",
    "                html = etree.HTML(str(soup))\n",
    "\n",
    "                list_subcategory = [subcategory.strip() for subcategory in html.xpath('//td[@class=\"nlabel\"]/a/text()')]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "                \n",
    "                list_url = ['https://www.rockauto.com'+url.strip() for url in html.xpath('//td[@class=\"niconspace ncollapsedicon\"]/a/@href')]\n",
    "                \n",
    "                # = = = = = = = = = = = = = = =\n",
    "                \n",
    "                crawler_status = 'ok'\n",
    "                \n",
    "                break\n",
    "                \n",
    "            except:\n",
    "                time.sleep(0.3)\n",
    "                continue\n",
    "\n",
    "        if crawler_status == 'ok':\n",
    "            df_temp = pd.DataFrame({'Tab_Label': input_.loc[i, 'Tab_Label'],\n",
    "                                    'No.': int(input_.loc[i, 'No.']),\n",
    "                                    'Category': input_.loc[i, 'Category'],\n",
    "                                    'Subcategory': list_subcategory,\n",
    "                                    'Url': list_url})\n",
    "\n",
    "            output_correct = pd.concat([output_correct, df_temp], ignore_index=True).fillna('')\n",
    "        else:\n",
    "            df_temp = pd.DataFrame([{'Tab_Label': input_.loc[i, 'Tab_Label'],\n",
    "                                     'No.': int(input_.loc[i, 'No.']),\n",
    "                                     'Category': input_.loc[i, 'Category'],\n",
    "                                     'Url': input_.loc[i, 'Url']}])\n",
    "    \n",
    "            output_error = pd.concat([output_error, df_temp], ignore_index=True).fillna('')\n",
    "\n",
    "        print(input_.loc[i, 'Category'] +  '  <->  [' + crawler_status + '] - 剩余数量：' + str(work.qsize()) + ' - 当前时间：' + datetime.now().strftime('%H:%M:%S'))\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "list_task = []\n",
    "for _ in range(20):\n",
    "    task = gevent.spawn(crawler)\n",
    "    list_task.append(task)\n",
    "gevent.joinall(list_task)\n",
    "\n",
    "print()\n",
    "print('爬虫输出中')\n",
    "output_correct = output_correct.drop_duplicates(ignore_index=True)\n",
    "output_correct = output_correct.sort_values(by=['No.', 'Subcategory'], ascending=[True, True])\n",
    "output_correct.to_excel('./2.subategory-' + datetime.now().strftime('%Y%m%d_%H%M%S') + '.xlsx', index=False)\n",
    "if len(output_error) != 0:\n",
    "    output_error = output_error.drop_duplicates(ignore_index=True)\n",
    "    output_error = output_error.sort_values(by=['No.'], ascending=[True])\n",
    "    output_error.to_excel('./subategory_error.xlsx', index=False)\n",
    "    print()\n",
    "    print('爬虫存在error')\n",
    "print()\n",
    "print('爬虫结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf8dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
