{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b786d7ed-adec-45a0-a457-744c96ab0d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数量：41\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 1-10.https://www.rockauto.com/en/parts/MELLING,S905,Oil Pump Sprocket,5589\n",
      "[剩余数量：36] - [当前时间：19:30:47]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 1-8.https://www.rockauto.com/en/parts/MELLING,717F,Oil Pump Chain,5568\n",
      "[剩余数量：35] - [当前时间：19:30:48]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 1-7.https://www.rockauto.com/en/parts/MELLING,S906A,Timing Cam Sprocket,5722\n",
      "[剩余数量：34] - [当前时间：19:30:48]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 1-1.https://www.rockauto.com/en/parts/MELLING,715F,Timing Chain,5724\n",
      "[剩余数量：33] - [当前时间：19:30:48]\n",
      "\n",
      "[状态：ok，尝试次数：2] - 100.00% - crawler_1 > 1-6.https://www.rockauto.com/en/parts/MELLING,S899,Timing Crank Sprocket,5723\n",
      "[剩余数量：32] - [当前时间：19:30:48]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 1-5.https://www.rockauto.com/en/parts/MELLING,BT7016,Oil Pump Chain Tensioner,11860\n",
      "[剩余数量：31] - [当前时间：19:30:49]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 1-3.https://www.rockauto.com/en/parts/MELLING,BT5514,Timing Chain Tensioner,5736\n",
      "[剩余数量：30] - [当前时间：19:30:49]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 10-1.https://www.rockauto.com/en/parts/MELLING,1025,Timing Chain,5724\n",
      "[剩余数量：29] - [当前时间：19:30:51]\n",
      "\n",
      "[状态：ok，尝试次数：2] - 100.00% - crawler_1 > 1-2.https://www.rockauto.com/en/parts/MELLING,BG5515,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：28] - [当前时间：19:30:51]\n",
      "\n",
      "[状态：ok，尝试次数：4] - 100.00% - crawler_1 > 1-4.https://www.rockauto.com/en/parts/MELLING,BT7015,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：27] - [当前时间：19:30:52]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 10-6.https://www.rockauto.com/en/parts/MELLING,S1261,Timing Crank Sprocket,5723\n",
      "[剩余数量：26] - [当前时间：19:30:52]\n",
      "\n",
      "[状态：ok，尝试次数：3] - 100.00% - crawler_1 > 1-9.https://www.rockauto.com/en/parts/MELLING,BG7019,Oil Pump Chain Guide,11859\n",
      "[剩余数量：25] - [当前时间：19:30:53]\n",
      "\n",
      "[状态：ok，尝试次数：3] - 100.00% - crawler_1 > 10-7.https://www.rockauto.com/en/parts/MELLING,S1290,Timing Idler Sprocket,10465\n",
      "[剩余数量：24] - [当前时间：19:30:54]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 10-4.https://www.rockauto.com/en/parts/MELLING,BT5077,Timing Chain Tensioner,5736\n",
      "[剩余数量：23] - [当前时间：19:30:54]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 10-9.https://www.rockauto.com/en/parts/MELLING,BG5063,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：22] - [当前时间：19:30:55]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 10-8.https://www.rockauto.com/en/parts/MELLING,BG5062,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：21] - [当前时间：19:30:55]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 10-3.https://www.rockauto.com/en/parts/MELLING,BT5079,Timing Chain Tensioner,5736\n",
      "[剩余数量：20] - [当前时间：19:30:56]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 5-3.https://www.rockauto.com/en/parts/MELLING,BG5054,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：19] - [当前时间：19:30:57]\n",
      "\n",
      "[状态：ok，尝试次数：2] - 100.00% - crawler_1 > 10-2.https://www.rockauto.com/en/parts/MELLING,1026,Timing Chain,5724\n",
      "[剩余数量：18] - [当前时间：19:30:57]\n",
      "\n",
      "[状态：ok，尝试次数：2] - 100.00% - crawler_1 > 5-2.https://www.rockauto.com/en/parts/MELLING,BG5053,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：17] - [当前时间：19:30:58]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 5-1.https://www.rockauto.com/en/parts/MELLING,722F,Timing Chain,5724\n",
      "[剩余数量：16] - [当前时间：19:30:58]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 10-5.https://www.rockauto.com/en/parts/MELLING,BT5078,Timing Chain Tensioner,5736\n",
      "[剩余数量：15] - [当前时间：19:30:59]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 5-6.https://www.rockauto.com/en/parts/MELLING,BT5069,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：14] - [当前时间：19:31:00]\n",
      "\n",
      "[状态：ok，尝试次数：3] - 100.00% - crawler_1 > 5-4.https://www.rockauto.com/en/parts/MELLING,BT5066,Timing Chain Tensioner,5736\n",
      "[剩余数量：13] - [当前时间：19:31:01]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 6-10.https://www.rockauto.com/en/parts/MELLING,S1276,Timing Cam Sprocket,5722\n",
      "[剩余数量：12] - [当前时间：19:31:01]\n",
      "\n",
      "[状态：ok，尝试次数：2] - 100.00% - crawler_1 > 5-7.https://www.rockauto.com/en/parts/MELLING,BT5070,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：11] - [当前时间：19:31:01]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 6-8.https://www.rockauto.com/en/parts/MELLING,S1251,Timing Crank Sprocket,5723\n",
      "[剩余数量：10] - [当前时间：19:31:02]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 7-9.https://www.rockauto.com/en/parts/MELLING,S1278,Timing Cam Sprocket,5722\n",
      "[剩余数量：9] - [当前时间：19:31:02]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 6-9.https://www.rockauto.com/en/parts/MELLING,S1274,Timing Cam Sprocket,5722\n",
      "[剩余数量：8] - [当前时间：19:31:02]\n",
      "\n",
      "[状态：ok，尝试次数：2] - 100.00% - crawler_1 > 5-5.https://www.rockauto.com/en/parts/MELLING,BT5068,Timing Chain Tensioner,5736\n",
      "[剩余数量：7] - [当前时间：19:31:03]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 8-5.https://www.rockauto.com/en/parts/MELLING,BT5618,Timing Chain Tensioner,5736\n",
      "[剩余数量：6] - [当前时间：19:31:05]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 8-6.https://www.rockauto.com/en/parts/MELLING,BT5619,Timing Chain Tensioner,5736\n",
      "[剩余数量：5] - [当前时间：19:31:05]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 8-10.https://www.rockauto.com/en/parts/MELLING,S960,Timing Cam Sprocket,5722\n",
      "[剩余数量：4] - [当前时间：19:31:05]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 8-4.https://www.rockauto.com/en/parts/MELLING,BG5623,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：3] - [当前时间：19:31:06]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 8-3.https://www.rockauto.com/en/parts/MELLING,BG5622,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：2] - [当前时间：19:31:06]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 8-7.https://www.rockauto.com/en/parts/MELLING,BT5620,Timing Chain Tensioner,5736\n",
      "[剩余数量：1] - [当前时间：19:31:07]\n",
      "\n",
      "[状态：ok，尝试次数：2] - 100.00% - crawler_1 > 8-1.https://www.rockauto.com/en/parts/MELLING,470,Timing Chain,5724\n",
      "[剩余数量：0] - [当前时间：19:31:09]\n",
      "\n",
      "[状态：ok，尝试次数：1] - 100.00% - crawler_1 > 8-9.https://www.rockauto.com/en/parts/MELLING,S959,Timing Crank Sprocket,5723\n",
      "[剩余数量：0] - [当前时间：19:31:09]\n",
      "\n",
      "[状态：ok，尝试次数：3] - 100.00% - crawler_1 > 8-8.https://www.rockauto.com/en/parts/MELLING,BT5621,Timing Chain Guide / Damper,5728\n",
      "[剩余数量：0] - [当前时间：19:31:09]\n",
      "\n",
      "[状态：ok，尝试次数：4] - 100.00% - crawler_1 > 8-2.https://www.rockauto.com/en/parts/MELLING,471,Timing Chain,5724\n",
      "[剩余数量：0] - [当前时间：19:31:12]\n",
      "\n",
      "[状态：ok，尝试次数：5] - 100.00% - crawler_1 > 8-11.https://www.rockauto.com/en/parts/MELLING,S961,Timing Idler Sprocket,10465\n",
      "[剩余数量：0] - [当前时间：19:31:16]\n",
      "\n",
      "输出ing...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████████████████████████| 1/1 [00:00<00:00, 3041.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gevent import monkey\n",
    "monkey.patch_all(thread=False)\n",
    "from gevent.queue import Queue\n",
    "import gevent\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists('./file/8.kit_part'):\n",
    "    shutil.rmtree('./file/8.kit_part')\n",
    "\n",
    "os.makedirs('./file/8.kit_part')\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../00.Tools')\n",
    "from crawler_configuration import get_header, get_proxy\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "import re\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "list_file = sorted(list(os.walk('./file/7.kit_part_number'))[0][2])\n",
    "while '.DS_Store' in list_file:\n",
    "    list_file.remove('.DS_Store')\n",
    "while '0.null.txt' in list_file:\n",
    "    list_file.remove('0.null.txt')\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "for file in list_file:\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    output_correct, output_error = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    input_ = pd.read_excel(f'./file/7.kit_part_number/{file}',\n",
    "                           header=0,\n",
    "                           dtype=str).fillna('')\n",
    "\n",
    "    input_ = input_[input_['Kit_JOIN_MPNTCPC'] != '']\n",
    "\n",
    "    input_ = input_.drop_duplicates(['Kit_JOIN_MPNTCPC'],\n",
    "                                    keep='first',\n",
    "                                    ignore_index=True)\n",
    "    input_ = input_.sort_values(by=['No'],\n",
    "                                ascending=[True],\n",
    "                                ignore_index=True)\n",
    "        \n",
    "    input_['No'] = input_['No'].astype(int)\n",
    "    input_['Kit_No'] = ['' if no == '' else int(no) for no in input_['Kit_No'].tolist()]\n",
    "    input_['Kit_Quantity'] = ['' if quantity == '' else int(quantity) for quantity in input_['Kit_Quantity'].tolist()]\n",
    "\n",
    "    print(f'总数量：{len(input_)}')\n",
    "    print()\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "\n",
    "    work = Queue()\n",
    "    for a in range(len(input_)):\n",
    "        work.put_nowait(a)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    def crawler():\n",
    "        global output_correct, output_error\n",
    "\n",
    "        while not work.empty():\n",
    "            a = work.get_nowait()\n",
    "\n",
    "            # = = = = = = = = = = = = = = =\n",
    "\n",
    "            crawler_status = 'error'\n",
    "\n",
    "            # = = = = = = = = = = = = = = =\n",
    "\n",
    "            try:\n",
    "                data = {'dopartsearch': '1',\n",
    "                        'partsearch[partnum][partsearch_007]': input_.loc[a, 'Kit_Part Number'],\n",
    "                        'partsearch[manufacturer][partsearch_007]': input_.loc[a, 'Kit_Manufacturer'],\n",
    "                        'partsearch[parttype][partsearch_007]': input_.loc[a, 'Kit_Type Code'],\n",
    "                        'partsearch[do][partsearch_007]': '1',\n",
    "                        'func': 'sendparttabsearch',\n",
    "                        'giveback': json.dumps({}),\n",
    "                        'api_json_request': '1'}\n",
    "\n",
    "                b = 0\n",
    "                while True:\n",
    "                    b += 1\n",
    "                    try:\n",
    "                        check_url = input_.loc[a, 'Kit_Url']\n",
    "                        \n",
    "                        resp = requests.post('https://www.rockauto.com/catalog/catalogapi.php',\n",
    "                                             data=data,\n",
    "                                             headers=get_header(),\n",
    "                                             proxies=get_proxy(),\n",
    "                                             timeout=(10, 10))\n",
    "\n",
    "                        if resp.status_code == 200:\n",
    "                            dict_ = resp.json()\n",
    "                            \n",
    "                            if 'redirect_to_url' not in dict_ and not dict_['giveback'] and 'collected_javascript' in dict_:\n",
    "                                break\n",
    "                    except KeyboardInterrupt:\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "                            \n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                soup = BeautifulSoup(dict_['searchnoderesults'], 'lxml')\n",
    "                html = etree.HTML(str(soup))\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_tbody = html.xpath('//tbody[contains(@id, \"listingcontainer[__GIP__\")]')\n",
    "                \n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_list_note = [tbody.xpath('./tr[1]/td[contains(@class, \"listing-inner-content\")]/div[@class=\"listing-text-row-moreinfo-truck\"]/span[@class=\"span-link-underline-remover\"]') for tbody in list_tbody]\n",
    "                list_list_note = [[etree.tostring(note).decode('utf-8') for note in list_note] if list_note else [] for list_note in list_list_note]\n",
    "                list_list_note = [[re.sub(r'<.*?>', '', note) for note in list_note] for list_note in list_list_note]\n",
    "                list_list_note = [[re.sub(r' +', ' ', note).strip() for note in list_note] for list_note in list_list_note]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_dict_note = []\n",
    "                for list_note in list_list_note:\n",
    "                    dict_note = {}\n",
    "                    for i, note in enumerate(list_note):\n",
    "                        dict_note[str(i)] = note\n",
    "                \n",
    "                    list_dict_note.append(dict_note)\n",
    "                \n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_list_note = [tbody.xpath('./tr[1]/td[contains(@class, \"listing-inner-content\")]/div[@class=\"listing-text-row\"]/span[contains(@title, \"Please make sure\")]') for tbody in list_tbody]\n",
    "                list_list_note = [[etree.tostring(text).decode('utf-8') for note in list_note for text in note.xpath('./span[@class=\"listing-footnote-text\"]')] if list_note else [] for list_note in list_list_note]\n",
    "                list_list_note = [[re.sub(r'<.*?>', '', note) for note in list_note] for list_note in list_list_note]\n",
    "                list_list_note = [[re.sub(r' +', ' ', note).strip() for note in list_note] for list_note in list_list_note]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_dict_note_2 = []\n",
    "                for list_note in list_list_note:\n",
    "                    dict_note = {}\n",
    "                    for i, note in enumerate(list_note):\n",
    "                        dict_note[str(i)] = note\n",
    "                \n",
    "                    list_dict_note_2.append(dict_note)\n",
    "    \n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_dict = [json.loads(tbody.xpath('./tr[1]/td[contains(@class, \"listing-inner-content\")]/input[contains(@id, \"listing_data_essential[__GIP__\")]/@value')[0]) for tbody in list_tbody]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_type_code = [dict_['parttype'] for dict_ in list_dict]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                array_index_type_code = np.where(np.array(list_type_code) == input_.loc[a, 'Kit_Type Code'])\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_part_code = [dict_['partkey'] for dict_ in list_dict]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_list_info = [tbody.xpath('./tr[1]/td[contains(@class, \"listing-inner-content\")]/div[@class=\"listing-text-row-moreinfo-truck\"]/a[@class=\"ra-btn ra-btn-moreinfo\"]') for tbody in list_tbody]\n",
    "                list_info = [list_info[0].xpath('./@href')[0].strip() if list_info else '' for list_info in list_list_info]\n",
    "                list_info = [info if info.startswith('https://www.rockauto.com/en/moreinfo.php?') else f'''https://www.rockauto.com/en/moreinfo.php?pk={part_code}&cc=0&pt={type_code}&Lennon=1''' for info, part_code, type_code in zip(list_info, list_part_code, list_type_code)]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_dict = [json.loads(tbody.xpath('./tr[1]/td/input[contains(@id, \"listing_data_supplemental[__GIP__\")]/@value')[0]) for tbody in list_tbody]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                array_index_part_number = np.where(np.array([dict_['partnumber'] for dict_ in list_dict]) == input_.loc[a, 'Kit_Part Number'])\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                array_index_manufacturer = np.where(np.array([dict_['catalogname'] for dict_ in list_dict]) == input_.loc[a, 'Kit_Manufacturer'])\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                array_index_part = np.intersect1d(np.intersect1d(array_index_type_code, array_index_part_number), array_index_manufacturer)\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                if len(array_index_part) == 1:\n",
    "                    index_part = array_index_part[0]\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                choose = list_dict[index_part]['paramdesc'].strip()\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_list_text = [td.xpath('./span[contains(@title, \"Replaces these Alternate\")]/text()') for td in list_tbody[index_part].xpath('./tr[1]/td[contains(@class, \"listing-inner-content\")]')]\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_oem = []\n",
    "                for list_text in list_list_text:\n",
    "                    if list_text:\n",
    "                        for text in list_text:\n",
    "                            list_oem += text.split(',')\n",
    "                        \n",
    "                list_oem = [oem.strip() for oem in list_oem]\n",
    "                    \n",
    "                while '' in list_oem:\n",
    "                    list_oem.remove('')\n",
    "                \n",
    "                oem = ';'.join(sorted(list(set(list_oem))))\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_src = list_tbody[index_part].xpath('./tr[1]/td/div[contains(@class, \"listing-image-space-occupy\")]/input[contains(@id, \"jsninlineimg[__GIP__\")]')\n",
    "                dict_ = json.loads(list_src[0].xpath('./@value')[0]) if list_src else {}\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                dict_src = {}\n",
    "                if dict_:\n",
    "                    list_src = dict_['Slots']\n",
    "                    for i, src in enumerate(list_src):\n",
    "                        dict_src[str(i)] = f'''https://www.rockauto.com{src['ImageData']['Full'].strip()}'''\n",
    "        \n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                price = list_tbody[index_part].xpath('./tr[1]/td[contains(@id, \"listingtd[__GIP__\") and contains(@id, \"__][price]\")]/span[contains(@id, \"dprice[__GIP__\") and contains(@id, \"__][td]\")]/span/span[contains(@id, \"dprice[__GIP__\") and contains(@id, \"__][v]\")]')\n",
    "                price = etree.tostring(price[0]).decode('utf-8') if price else ''\n",
    "                price = re.sub(r'<.*?>', '', price)\n",
    "                price = re.sub(r' +', ' ', price).strip()\n",
    "                dict_price = {'0': price}\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                td = list_tbody[index_part].xpath('./tr[1]/td[contains(@class, \"listing-inner-content\")]')[0]\n",
    "                list_option = [etree.tostring(option).decode('utf-8') for option in td.xpath('./div/div[contains(@class, \"listing-optionchoice-multiple-container\")]/span[contains(@id, \"ddrepl[optionchoice[__GIP__\") and contains(@id, \"__]][container]\")]/span[@class=\"hide-if-js\"]/select[contains(@id, \"optionchoice[__GIP__\") and contains(@id, \"__]\")]/option[@value!=\"\"]')]\n",
    "                list_option = [re.sub(r'<.*?>', '', option) for option in list_option]\n",
    "                list_option = [re.sub(r' +', ' ', option).strip() for option in list_option]\n",
    "                if list_option:\n",
    "                    dict_price['1'] = {}\n",
    "                    for i, option in enumerate(list_option):\n",
    "                        dict_price['1'][str(i)] = option\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                df_temp = pd.DataFrame([{'Kit_JOIN_MPNTCPC': input_.loc[a, 'Kit_JOIN_MPNTCPC'],\n",
    "                                         'Kit_Type': input_.loc[a, 'Kit_Type'],\n",
    "                                         'Kit_Manufacturer': input_.loc[a, 'Kit_Manufacturer'],\n",
    "                                         'Kit_Part Number': input_.loc[a, 'Kit_Part Number'],\n",
    "                                         'Kit_Vehicle': '',\n",
    "                                         'Kit_OEM': oem,\n",
    "                                         'Kit_Picture': '',\n",
    "                                         'Kit_Url': input_.loc[a, 'Kit_Url'],\n",
    "                                         'Kit_Json_Src': json.dumps(dict_src),\n",
    "                                         'Kit_Info': list_info[index_part],\n",
    "                                         'Kit_Choose': choose,\n",
    "                                         'Kit_Json_Price': json.dumps(dict_price),\n",
    "                                         'Kit_Json_Note 1': json.dumps(list_dict_note[index_part]),\n",
    "                                         'Kit_Json_Note 2': json.dumps(list_dict_note_2[index_part]),\n",
    "                                         'Kit_Type Code': input_.loc[a, 'Kit_Type Code'],\n",
    "                                         'Kit_Part Code': list_part_code[index_part]}])\n",
    "\n",
    "                output_correct = pd.concat([output_correct, df_temp], ignore_index=True).fillna('')\n",
    "\n",
    "                # = = = = = = = = = = = = = = =\n",
    "\n",
    "                crawler_status = 'ok'\n",
    "            except:\n",
    "                df_temp = pd.DataFrame([input_.iloc[a]]).reset_index(drop=True)\n",
    "                df_temp.loc[0, 'Check_Url'] = check_url\n",
    "                \n",
    "                output_error = pd.concat([output_error, df_temp], ignore_index=True).fillna('')\n",
    "\n",
    "            # = = = = = = = = = = = = = = =\n",
    "\n",
    "            if list_file.index(file) % 3 == 0 and list_file.index(file) != 0 and work.qsize() == 0 or work.qsize() % 1_000 == 0 and work.qsize() != 0:\n",
    "                clear_output()\n",
    "\n",
    "            print(f'''[状态：{crawler_status}，尝试次数：{b}] - {(list_file.index(file) + 1) / len(list_file) * 100:.2f}% - {file.removesuffix('.xlsx')} > {input_.loc[a, 'No']}-{input_.loc[a, 'Kit_No']}.{check_url}\\n[剩余数量：{work.qsize()}] - [当前时间：{datetime.now().strftime('%H:%M:%S')}]\\n''')\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    list_task = []\n",
    "    for _ in range(5):\n",
    "        task = gevent.spawn(crawler)\n",
    "        list_task.append(task)\n",
    "    gevent.joinall(list_task)\n",
    "\n",
    "    print('输出ing...')\n",
    "    print()\n",
    "    if not output_correct.empty:\n",
    "        output_correct = output_correct.sort_values(by=['Kit_JOIN_MPNTCPC'],\n",
    "                                                    ascending=[True],\n",
    "                                                    ignore_index=True)\n",
    "        output_correct.to_excel(f'''./file/8.kit_part/{file.removesuffix('.xlsx')}-{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx''', index=False)\n",
    "    if not output_error.empty:\n",
    "        output_error = output_error.sort_values(by=['No'],\n",
    "                                                ascending=[True],\n",
    "                                                ignore_index=True)\n",
    "        output_error.to_excel(f'''./file/{file.removesuffix('.xlsx')}-kit_part_error.xlsx''', index=False)\n",
    "        print('爬虫存在error')\n",
    "        print()\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "list_file = sorted(list(os.walk('./file/8.kit_part'))[0][2])\n",
    "while '.DS_Store' in list_file:\n",
    "    list_file.remove('.DS_Store')\n",
    "while '0.null.txt' in list_file:\n",
    "    list_file.remove('0.null.txt')\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for file in tqdm(list_file, desc='Progress', ncols=77):\n",
    "    os.rename(f'./file/8.kit_part/{file}',\n",
    "              f'''./file/8.kit_part/{re.sub(r'-[0-9]{8}_[0-9]{6}.xlsx$', '.xlsx', file)}''')\n",
    "\n",
    "print('Done ~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b85824-3eb7-4c9b-b273-da652c66cd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
