{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a52743a-d139-4667-b3b4-363cb166476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "if os.path.exists('./file/4.collate'):\n",
    "    shutil.rmtree('./file/4.collate')\n",
    "\n",
    "os.makedirs('./file/4.collate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e688525-cdaa-470c-a533-fb612881a181",
   "metadata": {},
   "source": [
    "# 1. Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7fb788-2e77-4500-b015-18b365a24a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawler_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 297.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "crawler_2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 867.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done ~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "list_file = sorted(list(os.walk('./file/3.oem'))[0][2])\n",
    "while '.DS_Store' in list_file:\n",
    "    list_file.remove('.DS_Store')\n",
    "while '0.null.txt' in list_file:\n",
    "    list_file.remove('0.null.txt')\n",
    "    \n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "for file in list_file:\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    input_ = pd.read_excel(f'./file/3.oem/{file}',\n",
    "                       header=0,\n",
    "                       dtype=str).fillna('')\n",
    "\n",
    "    input_['No'] = input_['No'].astype(int)\n",
    "    input_['Rating Count'] = input_['Rating Count'].astype(int)\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    list_column, list_column_description = input_.columns.tolist(), []\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    list_df = []\n",
    "    for i in tqdm(range(len(input_)), desc='Progress', ncols=77):\n",
    "        df_temp, dict_dict = pd.DataFrame([input_.iloc[i]]).reset_index(drop=True), json.loads(input_.loc[i, 'Json_Description'])\n",
    "\n",
    "        for dict_ in dict_dict.values():\n",
    "            for key, value in dict_.items():\n",
    "                if key in list_column:\n",
    "                    key = f'''{key} (Description)'''\n",
    "                \n",
    "                if key not in list_column_description:\n",
    "                    list_column_description.append(key)\n",
    "\n",
    "                if type(value) == dict:\n",
    "                    list_value = []\n",
    "                    for key_2, value_2 in value.items():\n",
    "                        list_value.append(f'''{int(key_2) + 1}. {value_2}''')\n",
    "                    df_temp.loc[0, key] = '\\n'.join(list_value)\n",
    "                else:\n",
    "                    df_temp.loc[0, key] = value\n",
    "    \n",
    "        list_df.append(df_temp)\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    output = pd.concat(list_df, ignore_index=True).fillna('')\n",
    "\n",
    "    output = output.sort_values(by=['No'],\n",
    "                                ascending=[True],\n",
    "                                ignore_index=True)\n",
    "\n",
    "    output[list_column[:10] + list_column[13:] + sorted(list_column_description) + list_column[10:13]].to_excel(f'./file/4.collate/{file}', index=False)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Done ~')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c7049-7ebe-4c62-874c-d1c440e5f1a8",
   "metadata": {},
   "source": [
    "# 2. Compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba81059-56d8-4ffb-8fa6-67b5d34894e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawler_1-vehicle.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 807.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "crawler_2-vehicle.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████| 10/10 [00:00<00:00, 812.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done ~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "list_file = sorted(list(os.walk('./file/3.vehicle'))[0][2])\n",
    "while '.DS_Store' in list_file:\n",
    "    list_file.remove('.DS_Store')\n",
    "while '0.null.txt' in list_file:\n",
    "    list_file.remove('0.null.txt')\n",
    "    \n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "for file in list_file:\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    input_ = pd.read_excel(f'./file/3.vehicle/{file}',\n",
    "                       header=0,\n",
    "                       dtype=str).fillna('')\n",
    "\n",
    "    input_['No'] = input_['No'].astype(int)\n",
    "    input_['Vehicle No'] = input_['Vehicle No'].astype(int)\n",
    "    input_['Year'] = input_['Year'].astype(int)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    input_2 = input_.drop_duplicates(['OEM Url'],\n",
    "                                     keep='first',\n",
    "                                     ignore_index=True)\n",
    "    input_2 = input_2.sort_values(by=['No'],\n",
    "                                  ascending=[True],\n",
    "                                  ignore_index=True)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    list_df = []\n",
    "    for i in tqdm(range(len(input_2)), desc='Progress', ncols=77):\n",
    "        df_temp = input_[input_['OEM Url'] == input_2.loc[i, 'OEM Url']].reset_index(drop=True)\n",
    "\n",
    "        dict_vehicle = {}\n",
    "        for j in range(len(df_temp)):\n",
    "            make, model, year = df_temp.loc[j, 'Make'], df_temp.loc[j, 'Model'], df_temp.loc[j, 'Year']\n",
    "    \n",
    "            if make not in dict_vehicle:\n",
    "                dict_vehicle[make] = {model: [year]}\n",
    "            elif model not in dict_vehicle[make]:\n",
    "                dict_vehicle[make][model] = [year]\n",
    "            elif year not in dict_vehicle[make][model]:\n",
    "                dict_vehicle[make][model].append(year)\n",
    "    \n",
    "        # = = = = = = = = = = = = = = =\n",
    "\n",
    "        list_vehicle = []\n",
    "        for make in dict_vehicle:\n",
    "            for model in dict_vehicle[make]:\n",
    "                year_begin = min(dict_vehicle[make][model])\n",
    "                year_end = max(dict_vehicle[make][model])\n",
    "                list_vehicle.append(f'{make} {model} {year_begin}' if year_begin == year_end else f'{make} {model} {year_begin}-{year_end}')\n",
    "\n",
    "        # = = = = = = = = = = = = = = =\n",
    "\n",
    "        df_temp = pd.DataFrame([{'No': input_2.loc[i, 'No'],\n",
    "                                 'SKU': input_2.loc[i, 'SKU'],\n",
    "                                 'OEM Url': input_2.loc[i, 'OEM Url'],\n",
    "                                 'Vehicle': '\\n'.join(sorted(list_vehicle))}])\n",
    "        list_df.append(df_temp)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    output = pd.concat(list_df, ignore_index=True).fillna('')\n",
    "\n",
    "    output = output.sort_values(by=['No'],\n",
    "                                ascending=[True],\n",
    "                                ignore_index=True)\n",
    "\n",
    "    output.to_excel(f'./file/4.collate/{file}', index=False)\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    print()\n",
    "\n",
    "print('Done ~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09555ca-b763-40cc-b060-c17a5d45abd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
