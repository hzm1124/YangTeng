{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ff4d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0730e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['menu_1.xlsx',\n",
       " 'menu_10.xlsx',\n",
       " 'menu_100.xlsx',\n",
       " 'menu_101.xlsx',\n",
       " 'menu_102.xlsx',\n",
       " 'menu_103.xlsx',\n",
       " 'menu_11.xlsx',\n",
       " 'menu_12.xlsx',\n",
       " 'menu_13.xlsx',\n",
       " 'menu_14.xlsx',\n",
       " 'menu_15.xlsx',\n",
       " 'menu_16.xlsx',\n",
       " 'menu_17.xlsx',\n",
       " 'menu_18.xlsx',\n",
       " 'menu_19.xlsx',\n",
       " 'menu_2.xlsx',\n",
       " 'menu_20.xlsx',\n",
       " 'menu_21.xlsx',\n",
       " 'menu_22.xlsx',\n",
       " 'menu_23.xlsx',\n",
       " 'menu_24.xlsx',\n",
       " 'menu_25.xlsx',\n",
       " 'menu_26.xlsx',\n",
       " 'menu_27.xlsx',\n",
       " 'menu_28.xlsx',\n",
       " 'menu_29.xlsx',\n",
       " 'menu_3.xlsx',\n",
       " 'menu_30.xlsx',\n",
       " 'menu_31.xlsx',\n",
       " 'menu_32.xlsx',\n",
       " 'menu_33.xlsx',\n",
       " 'menu_34.xlsx',\n",
       " 'menu_35.xlsx',\n",
       " 'menu_36.xlsx',\n",
       " 'menu_37.xlsx',\n",
       " 'menu_38.xlsx',\n",
       " 'menu_39.xlsx',\n",
       " 'menu_4.xlsx',\n",
       " 'menu_40.xlsx',\n",
       " 'menu_41.xlsx',\n",
       " 'menu_42.xlsx',\n",
       " 'menu_43.xlsx',\n",
       " 'menu_44.xlsx',\n",
       " 'menu_45.xlsx',\n",
       " 'menu_46.xlsx',\n",
       " 'menu_47.xlsx',\n",
       " 'menu_48.xlsx',\n",
       " 'menu_49.xlsx',\n",
       " 'menu_5.xlsx',\n",
       " 'menu_50.xlsx',\n",
       " 'menu_51.xlsx',\n",
       " 'menu_52.xlsx',\n",
       " 'menu_53.xlsx',\n",
       " 'menu_54.xlsx',\n",
       " 'menu_55.xlsx',\n",
       " 'menu_56.xlsx',\n",
       " 'menu_57.xlsx',\n",
       " 'menu_58.xlsx',\n",
       " 'menu_59.xlsx',\n",
       " 'menu_6.xlsx',\n",
       " 'menu_60.xlsx',\n",
       " 'menu_61.xlsx',\n",
       " 'menu_62.xlsx',\n",
       " 'menu_63.xlsx',\n",
       " 'menu_64.xlsx',\n",
       " 'menu_65.xlsx',\n",
       " 'menu_66.xlsx',\n",
       " 'menu_67.xlsx',\n",
       " 'menu_68.xlsx',\n",
       " 'menu_69.xlsx',\n",
       " 'menu_7.xlsx',\n",
       " 'menu_70.xlsx',\n",
       " 'menu_71.xlsx',\n",
       " 'menu_72.xlsx',\n",
       " 'menu_73.xlsx',\n",
       " 'menu_74.xlsx',\n",
       " 'menu_75.xlsx',\n",
       " 'menu_76.xlsx',\n",
       " 'menu_77.xlsx',\n",
       " 'menu_78.xlsx',\n",
       " 'menu_79.xlsx',\n",
       " 'menu_8.xlsx',\n",
       " 'menu_80.xlsx',\n",
       " 'menu_81.xlsx',\n",
       " 'menu_82.xlsx',\n",
       " 'menu_83.xlsx',\n",
       " 'menu_84.xlsx',\n",
       " 'menu_85.xlsx',\n",
       " 'menu_86.xlsx',\n",
       " 'menu_87.xlsx',\n",
       " 'menu_88.xlsx',\n",
       " 'menu_89.xlsx',\n",
       " 'menu_9.xlsx',\n",
       " 'menu_90.xlsx',\n",
       " 'menu_91.xlsx',\n",
       " 'menu_92.xlsx',\n",
       " 'menu_93.xlsx',\n",
       " 'menu_94.xlsx',\n",
       " 'menu_95.xlsx',\n",
       " 'menu_96.xlsx',\n",
       " 'menu_97.xlsx',\n",
       " 'menu_98.xlsx',\n",
       " 'menu_99.xlsx']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_menu = list(os.walk('./menu'))[0][2]\n",
    "if '.DS_Store' in list_menu:\n",
    "    list_menu.remove('.DS_Store')\n",
    "if '0.null.txt' in list_menu:\n",
    "    list_menu.remove('0.null.txt')\n",
    "    \n",
    "list_menu.sort()\n",
    "    \n",
    "list_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d818946e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数量：1\n",
      "\n",
      "[ok] - Scottsdale, Arizona - 459\n",
      "[尝试次数：1] - [menu_79.xlsx - 剩余数量：0] - [当前时间：14:17:56]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：1\n",
      "\n",
      "[ok] - Baton Rouge, Louisiana - 179\n",
      "[尝试次数：1] - [menu_80.xlsx - 剩余数量：0] - [当前时间：14:18:18]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：3\n",
      "\n",
      "[ok] - Garland, Texas - 183\n",
      "[尝试次数：1] - [menu_86.xlsx - 剩余数量：0] - [当前时间：14:18:41]\n",
      "\n",
      "[ok] - Garland, Texas - 117\n",
      "[尝试次数：1] - [menu_86.xlsx - 剩余数量：0] - [当前时间：14:18:45]\n",
      "\n",
      "[ok] - Garland, Texas - 139\n",
      "[尝试次数：1] - [menu_86.xlsx - 剩余数量：0] - [当前时间：14:18:48]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：2\n",
      "\n",
      "[ok] - Hialeah, Florida - 163\n",
      "[尝试次数：1] - [menu_87.xlsx - 剩余数量：0] - [当前时间：14:19:14]\n",
      "\n",
      "[ok] - Hialeah, Florida - 221\n",
      "[尝试次数：1] - [menu_87.xlsx - 剩余数量：0] - [当前时间：14:19:15]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：1\n",
      "\n",
      "[ok] - Chula Vista, California - 20\n",
      "[尝试次数：1] - [menu_89.xlsx - 剩余数量：0] - [当前时间：14:19:41]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：1\n",
      "\n",
      "[ok] - Reno, Nevada - 292\n",
      "[尝试次数：1] - [menu_91.xlsx - 剩余数量：0] - [当前时间：14:20:10]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：3\n",
      "\n",
      "[ok] - Rochester, New York - 335\n",
      "[尝试次数：1] - [menu_94.xlsx - 剩余数量：0] - [当前时间：14:20:31]\n",
      "\n",
      "[ok] - Rochester, New York - 333\n",
      "[尝试次数：1] - [menu_94.xlsx - 剩余数量：0] - [当前时间：14:20:31]\n",
      "\n",
      "[ok] - Rochester, New York - 334\n",
      "[尝试次数：1] - [menu_94.xlsx - 剩余数量：0] - [当前时间：14:20:31]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：1\n",
      "\n",
      "[ok] - Shreveport, Louisiana - 50\n",
      "[尝试次数：1] - [menu_98.xlsx - 剩余数量：0] - [当前时间：14:20:54]\n",
      "\n",
      "输出ing...\n",
      "\n",
      "Done ~\n",
      "总数量：423\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "2024-03-31T06:21:04Z\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 282\u001b[0m\n\u001b[1;32m    280\u001b[0m     task \u001b[38;5;241m=\u001b[39m gevent\u001b[38;5;241m.\u001b[39mspawn(crawler)\n\u001b[1;32m    281\u001b[0m     list_task\u001b[38;5;241m.\u001b[39mappend(task)\n\u001b[0;32m--> 282\u001b[0m \u001b[43mgevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_task\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m输出ing...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32msrc/gevent/greenlet.py:1065\u001b[0m, in \u001b[0;36mgevent._gevent_cgreenlet.joinall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/greenlet.py:1075\u001b[0m, in \u001b[0;36mgevent._gevent_cgreenlet.joinall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:250\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives.wait_on_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:287\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives.wait_on_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:185\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives._WaitIterator.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:176\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives._WaitIterator.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_waiter.py:195\u001b[0m, in \u001b[0;36mgevent._gevent_c_waiter.MultipleWaiter.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_waiter.py:154\u001b[0m, in \u001b[0;36mgevent._gevent_c_waiter.Waiter.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:61\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:61\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:65\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_gevent_c_greenlet_primitives.pxd:35\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives._greenlet_switch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param_menu in [\n",
    " 'menu_79.xlsx',\n",
    " 'menu_80.xlsx',\n",
    " 'menu_86.xlsx',\n",
    " 'menu_87.xlsx',\n",
    " 'menu_89.xlsx',\n",
    " 'menu_91.xlsx',\n",
    " 'menu_94.xlsx',\n",
    " 'menu_98.xlsx',\n",
    " 'menu_99.xlsx']:\n",
    "    \n",
    "    from gevent import monkey\n",
    "    monkey.patch_all(thread=False)\n",
    "    from gevent.queue import Queue\n",
    "    import gevent\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    output_correct = pd.DataFrame()\n",
    "    output_error = pd.DataFrame()\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    input_ = pd.read_excel('./menu/' + param_menu,\n",
    "                           header=0,\n",
    "                           dtype=str).fillna('')\n",
    "\n",
    "    print('总数量：' + str(len(input_)))\n",
    "    print()\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    from selenium.webdriver import Chrome\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "    from selenium.webdriver import ChromeOptions\n",
    "\n",
    "    option = ChromeOptions()\n",
    "\n",
    "    import sys\n",
    "    sys.path.append('../00.Tools')\n",
    "    import UA\n",
    "    import Proxy\n",
    "\n",
    "    option.add_experimental_option('useAutomationExtension', False)\n",
    "    option.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "    option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    option.add_argument('--disable-dev-shm-usage')\n",
    "    option.add_argument('--disable-gpu')\n",
    "    option.add_argument('--no-sandbox')\n",
    "    option.add_argument(UA.get_User_Agent_Selenium())\n",
    "    # option.add_argument('blink-settings=imagesEnabled=false')\n",
    "    # option.add_argument('--headless')\n",
    "    # option.add_extension(Proxy.get_Proxy_Selenium(''))\n",
    "\n",
    "    option.page_load_strategy = 'normal'\n",
    "\n",
    "    import time\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    from selenium.webdriver.support.wait import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.common.by import By\n",
    "\n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    from datetime import datetime\n",
    "    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    work = Queue()\n",
    "    for a in range(len(input_)):\n",
    "        work.put_nowait(a)\n",
    "        \n",
    "    # = = = = = = = = = = = = = = =\n",
    "    \n",
    "    def crawler():\n",
    "        global output_correct, output_error\n",
    "        \n",
    "        while not work.empty():\n",
    "            a = work.get_nowait()\n",
    "            \n",
    "            # = = = = = = = = = = = = = = =\n",
    "            \n",
    "            crawler_status = 'error'\n",
    "            for b in range(10):\n",
    "                try:\n",
    "                    \n",
    "                    browser = Chrome(service=Service('../../../chromedriver'), options=option)\n",
    "                    browser.maximize_window()\n",
    "                    browser.get(input_.loc[a, 'Url'])\n",
    "\n",
    "                    time.sleep(1)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "                    time.sleep(1)\n",
    "                    browser.execute_script('window.scrollTo(0, -document.body.scrollHeight);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.1);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.2);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.3);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.4);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.5);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.6);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.7);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.8);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight * 0.9);')\n",
    "                    time.sleep(0.2)\n",
    "                    browser.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    wait = WebDriverWait(browser, 60)\n",
    "                    wait.until(EC.presence_of_element_located((By.XPATH, '//h1[@class=\"css-hnttcw\"]')))\n",
    "                    name = browser.find_element(by=By.XPATH, value='//h1[@class=\"css-hnttcw\"]').text.strip()\n",
    "\n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    website = ''\n",
    "                    phone = ''\n",
    "                    location = ''\n",
    "                    wait.until(EC.presence_of_element_located((By.XPATH, '//section[@class=\"css-2entjo\"]/div[@class=\"css-s81j3n\"]/div[@class=\"css-djo2w\"]')))\n",
    "                    list_info = [div.get_attribute('textContent').strip() for div in browser.find_elements(by=By.XPATH, value='//section[@class=\"css-2entjo\"]/div[@class=\"css-s81j3n\"]/div[@class=\"css-djo2w\"]')]\n",
    "                    for info in list_info:\n",
    "                        if info.startswith('Business website'):\n",
    "                            website = info.replace('Business website', '')\n",
    "                        elif info.startswith('Phone number'):\n",
    "                            phone = info.replace('Phone number', '')\n",
    "                        elif info.startswith('Get Directions'):\n",
    "                            location = info.replace('Get Directions', '')\n",
    "                            \n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    score = ''\n",
    "                    review = ''\n",
    "                    list_evaluation = browser.find_elements(by=By.XPATH, value='//div[@class=\"arrange__09f24__LDfbs gutter-1-5__09f24__vMtpw vertical-align-middle__09f24__zU9sE css-9ul5p9\"]/div[@class=\"arrange-unit__09f24__rqHTg arrange-unit-fill__09f24__CUubG css-v3nuob\"]')\n",
    "                    if len(list_evaluation) != 0:\n",
    "                        if len(list_evaluation[0].find_elements(by=By.XPATH, value='./span[@class=\" css-1p9ibgf\"]')) != 0 and len(list_evaluation[0].find_elements(by=By.XPATH, value='./span[@class=\" css-1evauet\"]')) != 0:\n",
    "                            score = list_evaluation[0].find_element(by=By.XPATH, value='./span[@class=\" css-1p9ibgf\"]').text.strip()\n",
    "                            review = list_evaluation[0].find_element(by=By.XPATH, value='./span[@class=\" css-1evauet\"]').text.strip()\n",
    "                        elif len(list_evaluation[0].find_elements(by=By.XPATH, value='./span[@class=\" css-1fdy0l5\"]')) != 0 and len(list_evaluation[0].find_elements(by=By.XPATH, value='./span[@class=\" css-1x9ee72\"]')) != 0:\n",
    "                            score = list_evaluation[0].find_element(by=By.XPATH, value='./span[@class=\" css-1fdy0l5\"]').text.strip()\n",
    "                            review = list_evaluation[0].find_element(by=By.XPATH, value='./span[@class=\" css-1x9ee72\"]').text.strip()\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    claimed = ''\n",
    "                    list_claimed = browser.find_elements(by=By.XPATH, value='//span[@class=\" css-1xfc281\"]/span[@data-font-weight=\"semibold\"]/a')\n",
    "                    claimed = '\\n'.join([str(i+1) + '. ' + claimed.text.strip() for i, claimed in zip(range(len(list_claimed)), list_claimed)])\n",
    "\n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    verified = ''\n",
    "                    highlight = ''\n",
    "                    list_h4 = browser.find_elements(by=By.XPATH, value='//h4[@class=\"css-1p1tqzd\"]')\n",
    "                    for h4 in list_h4:\n",
    "                        if h4.text.strip() == 'Verified License':\n",
    "                            wait.until(EC.presence_of_element_located((By.XPATH, '//h4[@class=\"css-1p1tqzd\"]/ancestor::section[@class=\" css-ufd2i\"]/descendant::button[@class=\" css-1lxsk7j\"]')))\n",
    "                            h4.find_element(by=By.XPATH, value='./ancestor::section[@class=\" css-ufd2i\"]/descendant::button[@class=\" css-1lxsk7j\"]').click()\n",
    "                            wait.until(EC.presence_of_element_located((By.XPATH, '//table[@class=\"verified-license-table__09f24__zdm7b css-d4ecqf\"]/tbody/tr')))\n",
    "                            list_tr = browser.find_elements(by=By.XPATH, value='//table[@class=\"verified-license-table__09f24__zdm7b css-d4ecqf\"]/tbody/tr')\n",
    "                            for tr in list_tr:\n",
    "                                wait.until(EC.presence_of_element_located((By.XPATH, '//table[@class=\"verified-license-table__09f24__zdm7b css-d4ecqf\"]/tbody/tr/td')))\n",
    "                                verified += tr.find_element(by=By.XPATH, value='./td[1]').text.strip() + ': ' + tr.find_element(by=By.XPATH, value='./td[2]').text.strip() + '\\n'\n",
    "                            wait.until(EC.presence_of_element_located((By.XPATH, '//button[@aria-label=\"Close\"]')))\n",
    "                            browser.find_elements(by=By.XPATH, value='//button[@aria-label=\"Close\"]')[-1].click()\n",
    "\n",
    "                        elif h4.text.strip() == 'Highlights from the Business':\n",
    "                            wait.until(EC.presence_of_element_located((By.XPATH, '//h4[@class=\"css-1p1tqzd\"]/ancestor::section[@class=\" css-ufd2i\"]/div[2]/div')))\n",
    "                            list_div = h4.find_elements(by=By.XPATH, value='./ancestor::section[@class=\" css-ufd2i\"]/div[2]/div')\n",
    "                            highlight = '\\n'.join([str(i+1) + '. ' + div.text.strip() for i, div in zip(range(len(list_div)), list_div)])\n",
    "\n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    service = ''\n",
    "                    list_button = browser.find_elements(by=By.XPATH, value='//section[@aria-label=\"Services Offered\"]/button[@class=\" css-r3lhny\"]')\n",
    "                    while len(list_button) != 0:\n",
    "                        list_button[0].click()\n",
    "                        time.sleep(3)\n",
    "                        list_button = browser.find_elements(by=By.XPATH, value='//section[@aria-label=\"Services Offered\"]/button[@class=\" css-r3lhny\"]')\n",
    "\n",
    "                    list_div = browser.find_elements(by=By.XPATH, value='//section[@aria-label=\"Services Offered\"]/div[2]/div/div')\n",
    "\n",
    "                    service = '\\n'.join([str(i+1) + '. ' + div.text.strip() for i, div in zip(range(len(list_div)), list_div)])\n",
    "\n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    hour = ''\n",
    "                    list_tr = browser.find_elements(by=By.XPATH, value='//div[@id=\"location-and-hours\"]/section/div[2]/div[2]/descendant::tr[@class=\" css-29kerx\"]')\n",
    "                    for tr in list_tr:\n",
    "                        if tr.text.startswith('Mon\\n') or tr.text.startswith('Tue\\n') or tr.text.startswith('Wed\\n') or tr.text.startswith('Thu\\n') or tr.text.startswith('Fri\\n') or tr.text.startswith('Sat\\n') or tr.text.startswith('Sun\\n'):\n",
    "                            hour += tr.find_element(by=By.XPATH, value='./th').text.strip() + ' ' + tr.find_element(by=By.XPATH, value='./td[1]').text.strip() + '\\n'\n",
    "\n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    amenities= ''\n",
    "                    list_button = browser.find_elements(by=By.XPATH, value='//section[@aria-label=\"Amenities and More\"]/div[2]/button')\n",
    "                    if len(list_button) != 0 and list_button[0].get_attribute('data-button') != None and list_button[0].get_attribute('data-button').strip() == 'true':\n",
    "                        list_button[0].click()\n",
    "                        time.sleep(3)\n",
    "\n",
    "                    list_div = browser.find_elements(by=By.XPATH, value='//section[@aria-label=\"Amenities and More\"]/div[2]/div[1]/div/div/div/div')\n",
    "\n",
    "                    amenities = '\\n'.join([str(i+1) + '. ' + div.text.strip() for i, div in zip(range(len(list_div)), list_div)])\n",
    "                    \n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    wait.until(EC.presence_of_element_located((By.XPATH, '//meta[@property=\"og:url\"]')))\n",
    "                    url = browser.find_element(by=By.XPATH, value='//meta[@property=\"og:url\"]').get_attribute('content').strip()\n",
    "\n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    df_temp = pd.DataFrame([{'序号': int(input_.loc[a, '序号']),\n",
    "                                             'City_No.': int(input_.loc[a, 'City_No.']),\n",
    "                                             'City': input_.loc[a, 'City'],\n",
    "                                             'Page': int(input_.loc[a, 'Page']),\n",
    "                                             'No.': int(input_.loc[a, 'No.']),\n",
    "                                             'Tab': input_.loc[a, 'Tab'],\n",
    "                                             'Name': name,\n",
    "                                             'Website': website,\n",
    "                                             'Phone': phone,\n",
    "                                             'Location': location,\n",
    "                                             'Score': score,\n",
    "                                             'Review': review,\n",
    "                                             'Claimed': claimed,\n",
    "                                             'Verified': verified.strip(),\n",
    "                                             'Highlight': highlight,\n",
    "                                             'Service': service,\n",
    "                                             'Hour': hour.strip(),\n",
    "                                             'Amenities': amenities,\n",
    "                                             'Url': url}])\n",
    "\n",
    "                    browser.quit()\n",
    "\n",
    "                    output_correct = pd.concat([output_correct, df_temp], ignore_index=True).fillna('')\n",
    "                    \n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "                    crawler_status = 'ok'\n",
    "                    \n",
    "                    break\n",
    "                except:\n",
    "                    browser.quit()\n",
    "                    time.sleep(0.3)\n",
    "                    continue\n",
    "                    \n",
    "                    # = = = = = = = = = = = = = = =\n",
    "                    \n",
    "            if crawler_status == 'error':\n",
    "                df_temp = pd.DataFrame([{'序号': int(input_.loc[a, '序号']),\n",
    "                                         'City_No.': int(input_.loc[a, 'City_No.']),\n",
    "                                         'City': input_.loc[a, 'City'],\n",
    "                                         'Page': int(input_.loc[a, 'Page']),\n",
    "                                         'No.': int(input_.loc[a, 'No.']),\n",
    "                                         'Tab': input_.loc[a, 'Tab'],\n",
    "                                         'Url': input_.loc[a, 'Url']}])\n",
    "\n",
    "                output_error = pd.concat([output_error, df_temp], ignore_index=True).fillna('')\n",
    "                \n",
    "            # = = = = = = = = = = = = = = =\n",
    "            \n",
    "            print('[' + crawler_status + '] - ' + input_.loc[a, 'City'] + ' - ' + input_.loc[a, '序号'] +  '\\n[尝试次数：' + str(b+1) + '] - [' + param_menu + ' - 剩余数量：' + str(work.qsize()) + '] - [当前时间：' + datetime.now().strftime('%H:%M:%S') + ']\\n')\n",
    "                    \n",
    "    # = = = = = = = = = = = = = = =\n",
    "            \n",
    "    list_task = []\n",
    "    for _ in range(7):\n",
    "        task = gevent.spawn(crawler)\n",
    "        list_task.append(task)\n",
    "    gevent.joinall(list_task)\n",
    "\n",
    "    print('输出ing...')\n",
    "    print()\n",
    "    output_correct = output_correct.drop_duplicates(ignore_index=True)\n",
    "    output_correct = output_correct.sort_values(by=['序号'], ascending=[True]).reset_index(drop=True)\n",
    "    output_correct.to_excel('./part/part_' + param_menu.split('.')[0].split('_')[1] + '-' + datetime.now().strftime('%Y%m%d_%H%M%S') + '.xlsx', index=False)\n",
    "    if len(output_error) != 0:\n",
    "        output_error = output_error.drop_duplicates(ignore_index=True)\n",
    "        output_error = output_error.sort_values(by=['No.'], ascending=[True]).reset_index(drop=True)\n",
    "        output_error.to_excel('./part/part_' + param_menu.split('.')[0].split('_')[1] + '_error.xlsx', index=False)\n",
    "        print('爬虫存在error')\n",
    "        print()\n",
    "    print('Done ~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7cd25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
