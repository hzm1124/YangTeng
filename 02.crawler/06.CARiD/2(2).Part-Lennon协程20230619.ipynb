{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e3d35e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数量：947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "2023-07-10T07:35:36Z\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 184\u001b[0m\n\u001b[1;32m    182\u001b[0m     task \u001b[38;5;241m=\u001b[39m gevent\u001b[38;5;241m.\u001b[39mspawn(crawler)\n\u001b[1;32m    183\u001b[0m     list_task\u001b[38;5;241m.\u001b[39mappend(task)\n\u001b[0;32m--> 184\u001b[0m \u001b[43mgevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_task\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./part.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32msrc/gevent/greenlet.py:1065\u001b[0m, in \u001b[0;36mgevent._gevent_cgreenlet.joinall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/greenlet.py:1075\u001b[0m, in \u001b[0;36mgevent._gevent_cgreenlet.joinall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:250\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives.wait_on_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:287\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives.wait_on_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:185\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives._WaitIterator.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_hub_primitives.py:176\u001b[0m, in \u001b[0;36mgevent._gevent_c_hub_primitives._WaitIterator.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_waiter.py:195\u001b[0m, in \u001b[0;36mgevent._gevent_c_waiter.MultipleWaiter.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_waiter.py:154\u001b[0m, in \u001b[0;36mgevent._gevent_c_waiter.Waiter.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:61\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:61\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_greenlet_primitives.py:65\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/_gevent_c_greenlet_primitives.pxd:35\u001b[0m, in \u001b[0;36mgevent._gevent_c_greenlet_primitives._greenlet_switch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gevent import monkey\n",
    "monkey.patch_all()\n",
    "from gevent.queue import Queue\n",
    "import gevent\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "import pandas as pd\n",
    "from selenium.webdriver import ChromeOptions\n",
    "\n",
    "option = ChromeOptions()\n",
    "option.add_experimental_option('useAutomationExtension', False)\n",
    "option.add_argument('blink-settings=imagesEnabled=false')\n",
    "option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "option.add_argument('--disable-dev-shm-usage')\n",
    "option.add_argument('--disable-gpu')\n",
    "option.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "# option.add_argument('--headless')\n",
    "option.add_argument('--no-sandbox')\n",
    "option.add_argument('--proxy-server=http://u431.kdltps.com:15818')\n",
    "option.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36')\n",
    "option.page_load_strategy = 'eager'\n",
    "\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "df_menu = pd.read_excel('./menu.xlsx', header=0)\n",
    "list_url = df_menu['Url'].to_list()\n",
    "\n",
    "print('总数量：' + str(len(list_url)))\n",
    "print()\n",
    "\n",
    "work = Queue()\n",
    "for url in list_url:\n",
    "    work.put_nowait(url)\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "df = pd.DataFrame(columns=['Url',\n",
    "                           'Title',\n",
    "                           'mpn',\n",
    "                           'Brand',\n",
    "                           'Part_Number',\n",
    "                           'UPC',\n",
    "                           'Vehicle',\n",
    "                           'Src',\n",
    "                           'status'])\n",
    "\n",
    "# = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "def crawler():\n",
    "    global df\n",
    "    \n",
    "    while not work.empty():\n",
    "        url = work.get_nowait()\n",
    "        \n",
    "        status = 'error'\n",
    "        for _ in range(31):\n",
    "            try:\n",
    "                browser = Chrome(service=Service('../../../chromedriver'), options=option)\n",
    "                browser.maximize_window()\n",
    "                \n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "                browser.get(url)\n",
    "                \n",
    "                time.sleep(5)\n",
    "                \n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                wait = WebDriverWait(browser, 60)\n",
    "                wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"prod-title js-prod-title\"]/h1[@class=\"name\"]')))\n",
    "                title = browser.find_element(by=By.XPATH, value='//div[@class=\"prod-title js-prod-title\"]/h1[@class=\"name\"]').text\n",
    "\n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                list_row = browser.find_element(by=By.XPATH, value='//div[@class=\"prod-title js-prod-title\"]').text.split('|')\n",
    "                mpn = ''\n",
    "                for row in list_row:\n",
    "                    if row.startswith('Item # mpn'):\n",
    "                        mpn = row.split('Item # mpn')[1]\n",
    "\n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"prod_offer\"]')))\n",
    "                list_offer = browser.find_elements(by=By.XPATH, value='//div[@class=\"prod_offer\"]/div[@class=\"prod-offer-item\"]')\n",
    "\n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                brand = ''\n",
    "                part_number = ''\n",
    "                upc = ''\n",
    "                for offer in list_offer:\n",
    "                    if offer.text.startswith('Brand:'):\n",
    "                        brand = offer.text.split('Brand:')[1]\n",
    "                    elif offer.text.startswith('Part Number:'):\n",
    "                        part_number = offer.text.split('Part Number:')[1]\n",
    "                    elif offer.text.startswith('UPC:'):\n",
    "                        upc = offer.text.split('UPC:')[1]\n",
    "\n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                js = '''let list_expand = document.querySelectorAll('div[class=\"mmy-row\"]');\n",
    "                for(let i=0; i<list_expand.length; i++) {\n",
    "                        list_expand[i].getElementsByClassName('mmy-row-expand')[0].click();\n",
    "                }'''\n",
    "\n",
    "                browser.execute_script(js)\n",
    "\n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"prod-section-content\"]')))\n",
    "                list_row = browser.find_elements(by=By.XPATH, value='//div[@class=\"prod-section-content\"]')\n",
    "\n",
    "                list_vehicle = []\n",
    "                for row in list_row:\n",
    "                    if row.text.startswith('Vehicle Fitment'):\n",
    "                        list_make = row.find_elements(by=By.XPATH, value='./descendant::div[@class=\"mmy-row-title pointer js-mmy-row-expand\"]')\n",
    "                        for make in list_make:\n",
    "                            list_vehicle += [make.text + ' ' + model_year.text for model_year in make.find_elements(by=By.XPATH, value='./following-sibling::div[@class=\"mmy-row-description\"]/descendant::div[@class=\"mmy-subrow-title\"]')]\n",
    "\n",
    "                vehicle = '\\n'.join(list_vehicle)\n",
    "\n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                wait.until(EC.presence_of_element_located((By.XPATH, '//a[@class=\"product-image-main\"]')))\n",
    "                src = browser.find_element(by=By.XPATH, value='//a[@class=\"product-image-main\"]').get_attribute('href')\n",
    "\n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "                \n",
    "                status = 'ok'\n",
    "                df_temp = pd.DataFrame([{'Url': url,\n",
    "                                         'Title': title,\n",
    "                                         'mpn': mpn,\n",
    "                                         'Brand': brand,\n",
    "                                         'Part_Number': part_number,\n",
    "                                         'UPC': upc,\n",
    "                                         'Vehicle': vehicle,\n",
    "                                         'Src': src,\n",
    "                                         'status': 'ok'}])\n",
    "                \n",
    "                # = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "                list_row = [row.text for row in browser.find_elements(by=By.XPATH, value='//table[@class=\"spec-stripped-table\"]/tbody/tr/td')]\n",
    "\n",
    "                start = ''\n",
    "                for row in list_row:\n",
    "                    if ':' in row:\n",
    "                        name_value = row.split(': ')\n",
    "                        df_temp[(start + ' ' + name_value[0]).strip().lower()] = ': '.join(name_value[1:])\n",
    "                    else:\n",
    "                        start = row\n",
    "                        \n",
    "                browser.quit()\n",
    "\n",
    "                break\n",
    "\n",
    "            except:\n",
    "                time.sleep(3)\n",
    "                continue\n",
    "\n",
    "        # = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "        if status == 'error':\n",
    "            df_temp = pd.DataFrame([{'Url': url,\n",
    "                                     'status': 'error'}])\n",
    "\n",
    "        df = pd.concat([df, df_temp], ignore_index=True).fillna('')\n",
    "        \n",
    "        print(url +  '  <->  [' + status + '] - 剩余数量：' + str(work.qsize()))\n",
    "        \n",
    "# = = = = = = = = = = = = = = = = = =\n",
    "\n",
    "list_task = []\n",
    "for _ in range(9):\n",
    "    task = gevent.spawn(crawler)\n",
    "    list_task.append(task)\n",
    "gevent.joinall(list_task)\n",
    "\n",
    "df.to_excel('./part.xlsx', index=False)\n",
    "print()\n",
    "print('搞定')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9791f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
